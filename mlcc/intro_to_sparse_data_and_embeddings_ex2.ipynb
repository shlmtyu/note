{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intro_to_sparse_data_and_embeddings_ex2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"PQ17MK7YJ2Fk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":474},"outputId":"3769686e-0555-483a-846d-2444bd938e88","executionInfo":{"status":"ok","timestamp":1534732639495,"user_tz":-480,"elapsed":33930,"user":{"displayName":"joyce li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100989403678002079373"}}},"cell_type":"code","source":["from __future__ import print_function\n","\n","import collections\n","import io\n","import math\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from IPython import display\n","from sklearn import metrics\n","\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","train_url = 'https://dl.google.com/mlcc/mledu-datasets/sparse-data-embedding/train.tfrecord'\n","train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n","test_url = 'https://dl.google.com/mlcc/mledu-datasets/sparse-data-embedding/test.tfrecord'\n","test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)\n","\n","def _parse_function(record):\n","  \"\"\"Extracts features and labels.\n","  \n","  Args:\n","    record: File path to a TFRecord file    \n","  Returns:\n","    A `tuple` `(labels, features)`:\n","      features: A dict of tensors representing the features\n","      labels: A tensor with the corresponding labels.\n","  \"\"\"\n","  features = {\n","    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n","    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n","  }\n","  \n","  parsed_features = tf.parse_single_example(record, features)\n","  \n","  terms = parsed_features['terms'].values\n","  labels = parsed_features['labels']\n","\n","  return  {'terms':terms}, labels\n","\n","# Create the Dataset object\n","ds = tf.data.TFRecordDataset(train_path)\n","# Map features and labels with the parse function\n","ds = ds.map(_parse_function)\n","\n","ds\n","\n","# Create an input_fn that parses the tf.Examples from the given files,\n","# and split them into features and targets.\n","def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n","  \n","  # Same code as above; create a dataset and map features and labels\n","  ds = tf.data.TFRecordDataset(input_filenames)\n","  ds = ds.map(_parse_function)\n","\n","  if shuffle:\n","    ds = ds.shuffle(10000)\n","\n","  # Our feature data is variable-length, so we pad and batch\n","  # each field of the dataset structure to whatever size is necessary     \n","  ds = ds.padded_batch(25, ds.output_shapes)\n","  \n","  ds = ds.repeat(num_epochs)\n","\n","  \n","  # Return the next batch of data\n","  features, labels = ds.make_one_shot_iterator().get_next()\n","  return features, labels\n","\n","# 54 informative terms that compose our model vocabulary \n","informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n","                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n","                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n","                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n","                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n","                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n","                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n","                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n","                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n","                     \"drama\", \"family\", \"man\", \"woman\", \"boy\", \"girl\")\n","\n","terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)\n","\n","my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n","my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n","\n","feature_columns = [ terms_feature_column ]\n","\n","##################### Here's what we changed ##################################\n","classifier = tf.estimator.DNNClassifier(                                      #\n","  feature_columns=[tf.feature_column.indicator_column(terms_feature_column)], #\n","  hidden_units=[20,20],                                                       #\n","  optimizer=my_optimizer,                                                     #\n",")                                                                             #\n","###############################################################################\n","\n","try:\n","  classifier.train(\n","    input_fn=lambda: _input_fn([train_path]),\n","    steps=1000)\n","\n","  evaluation_metrics = classifier.evaluate(\n","    input_fn=lambda: _input_fn([train_path]),\n","    steps=1)\n","  print(\"Training set metrics:\")\n","  for m in evaluation_metrics:\n","    print(m, evaluation_metrics[m])\n","  print(\"---\")\n","\n","  evaluation_metrics = classifier.evaluate(\n","    input_fn=lambda: _input_fn([test_path]),\n","    steps=1)\n","\n","  print(\"Test set metrics:\")\n","  for m in evaluation_metrics:\n","    print(m, evaluation_metrics[m])\n","  print(\"---\")\n","except ValueError as err:\n","  print(err)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Training set metrics:\n","accuracy 0.8\n","accuracy_baseline 0.52\n","auc 0.87820506\n","auc_precision_recall 0.839794\n","average_loss 0.4307514\n","label/mean 0.48\n","loss 10.768785\n","precision 0.7692308\n","prediction/mean 0.44387236\n","recall 0.8333333\n","global_step 1000\n","---\n","Test set metrics:\n","accuracy 0.84\n","accuracy_baseline 0.56\n","auc 0.95454544\n","auc_precision_recall 0.96293813\n","average_loss 0.3256379\n","label/mean 0.56\n","loss 8.140947\n","precision 0.9166667\n","prediction/mean 0.4714518\n","recall 0.78571427\n","global_step 1000\n","---\n"],"name":"stdout"}]}]}