{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"intro_to_sparse_data_and_embeddings_ex1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"BYK6aJUlIQMY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":474},"outputId":"151dbdcc-36a2-4acf-c366-16442478eda4","executionInfo":{"status":"ok","timestamp":1534731791210,"user_tz":-480,"elapsed":30801,"user":{"displayName":"joyce li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100989403678002079373"}}},"cell_type":"code","source":["from __future__ import print_function\n","\n","import collections\n","import io\n","import math\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from IPython import display\n","from sklearn import metrics\n","\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","train_url = 'https://dl.google.com/mlcc/mledu-datasets/sparse-data-embedding/train.tfrecord'\n","train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n","test_url = 'https://dl.google.com/mlcc/mledu-datasets/sparse-data-embedding/test.tfrecord'\n","test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)\n","\n","def _parse_function(record):\n","  \"\"\"Extracts features and labels.\n","  \n","  Args:\n","    record: File path to a TFRecord file    \n","  Returns:\n","    A `tuple` `(labels, features)`:\n","      features: A dict of tensors representing the features\n","      labels: A tensor with the corresponding labels.\n","  \"\"\"\n","  features = {\n","    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n","    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n","  }\n","  \n","  parsed_features = tf.parse_single_example(record, features)\n","  \n","  terms = parsed_features['terms'].values\n","  labels = parsed_features['labels']\n","\n","  return  {'terms':terms}, labels\n","\n","# Create an input_fn that parses the tf.Examples from the given files,\n","# and split them into features and targets.\n","def _input_fn(input_filenames, num_epochs=None, shuffle=True):\n","  \n","  # Same code as above; create a dataset and map features and labels\n","  ds = tf.data.TFRecordDataset(input_filenames)\n","  ds = ds.map(_parse_function)\n","\n","  if shuffle:\n","    ds = ds.shuffle(10000)\n","\n","  # Our feature data is variable-length, so we pad and batch\n","  # each field of the dataset structure to whatever size is necessary     \n","  ds = ds.padded_batch(25, ds.output_shapes)\n","  \n","  ds = ds.repeat(num_epochs)\n","\n","  \n","  # Return the next batch of data\n","  features, labels = ds.make_one_shot_iterator().get_next()\n","  return features, labels\n","\n","# 54 informative terms that compose our model vocabulary \n","informative_terms = (\"bad\", \"great\", \"best\", \"worst\", \"fun\", \"beautiful\",\n","                     \"excellent\", \"poor\", \"boring\", \"awful\", \"terrible\",\n","                     \"definitely\", \"perfect\", \"liked\", \"worse\", \"waste\",\n","                     \"entertaining\", \"loved\", \"unfortunately\", \"amazing\",\n","                     \"enjoyed\", \"favorite\", \"horrible\", \"brilliant\", \"highly\",\n","                     \"simple\", \"annoying\", \"today\", \"hilarious\", \"enjoyable\",\n","                     \"dull\", \"fantastic\", \"poorly\", \"fails\", \"disappointing\",\n","                     \"disappointment\", \"not\", \"him\", \"her\", \"good\", \"time\",\n","                     \"?\", \".\", \"!\", \"movie\", \"film\", \"action\", \"comedy\",\n","                     \"drama\", \"family\", \"man\", \"woman\", \"boy\", \"girl\")\n","\n","terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"terms\", vocabulary_list=informative_terms)\n","\n","my_optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n","my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n","\n","feature_columns = [ terms_feature_column ]\n","\n","\n","classifier = tf.estimator.LinearClassifier(\n","  feature_columns=feature_columns,\n","  optimizer=my_optimizer,\n",")\n","\n","classifier.train(\n","  input_fn=lambda: _input_fn([train_path]),\n","  steps=1000)\n","\n","evaluation_metrics = classifier.evaluate(\n","  input_fn=lambda: _input_fn([train_path]),\n","  steps=1000)\n","print(\"Training set metrics:\")\n","for m in evaluation_metrics:\n","  print(m, evaluation_metrics[m])\n","print(\"---\")\n","\n","evaluation_metrics = classifier.evaluate(\n","  input_fn=lambda: _input_fn([test_path]),\n","  steps=1000)\n","\n","print(\"Test set metrics:\")\n","for m in evaluation_metrics:\n","  print(m, evaluation_metrics[m])\n","print(\"---\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Training set metrics:\n","accuracy 0.78672\n","accuracy_baseline 0.5\n","auc 0.8716411\n","auc_precision_recall 0.86141074\n","average_loss 0.45362526\n","label/mean 0.5\n","loss 11.3406315\n","precision 0.74387586\n","prediction/mean 0.5312065\n","recall 0.87456\n","global_step 1000\n","---\n","Test set metrics:\n","accuracy 0.7832\n","accuracy_baseline 0.5\n","auc 0.8697791\n","auc_precision_recall 0.8580655\n","average_loss 0.45435756\n","label/mean 0.5\n","loss 11.358939\n","precision 0.741243\n","prediction/mean 0.5297669\n","recall 0.87016\n","global_step 1000\n","---\n"],"name":"stdout"}]}]}